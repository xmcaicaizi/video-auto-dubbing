// Workerå®¢æˆ·ç«¯çš„å®Œæ•´ä¿®æ”¹ç‰ˆæœ¬
// æ–‡ä»¶: worker/internal/tts/vllm_client.go

package tts

import (
	"bytes"
	"context"
	"encoding/base64"
	"encoding/json"
	"fmt"
	"io"
	"mime/multipart"
	"net/http"
	"path/filepath"
	"time"

	"vedio/shared/config"

	"go.uber.org/zap"
)

// VLLMClient handles TTS API calls to index-tts-vllm service.
// It supports both the native API and OpenAI-compatible API.
type VLLMClient struct {
	baseURL string
	apiKey  string
	client  *http.Client
	logger  *zap.Logger
}

// NewVLLMClient creates a new index-tts-vllm client.
func NewVLLMClient(cfg config.TTSConfig, logger *zap.Logger) *VLLMClient {
	return &VLLMClient{
		baseURL: cfg.URL,
		apiKey:  cfg.APIKey,
		client: &http.Client{
			Timeout: 60 * time.Second, // å¢åŠ è¶…æ—¶æ—¶é—´ï¼Œå› ä¸ºéŸ³é¢‘ä¸Šä¼ å¯èƒ½è¾ƒæ…¢
		},
		logger: logger,
	}
}

// SynthesisRequest represents a TTS synthesis request.
type SynthesisRequest struct {
	Text           string `json:"text"`
	SpeakerID      string `json:"speaker_id,omitempty"`
	PromptAudioURL string `json:"prompt_audio_url,omitempty"` // ğŸ”¥ å…³é”®ï¼šåŸå§‹éŸ³é¢‘URL
	ResponseFormat string `json:"response_format,omitempty"`
	Speed          float32 `json:"speed,omitempty"`
}

// Reference: api_example_v2.py - æ›´æ–°ç»“æ„ä½“æ”¯æŒéŸ³è‰²å…‹éš†
type indexTTSV2Request struct {
	Text                        string    `json:"text"`
	SpkAudioPath                string    `json:"spk_audio_path"`                           // Required: speaker reference audio path
	EmoControlMethod            int       `json:"emo_control_method,omitempty"`             // 0=same as spk, 1=ref audio, 2=vector, 3=text
	EmoRefPath                  string    `json:"emo_ref_path,omitempty"`                   // Emotion reference audio path
	EmoWeight                   float64   `json:"emo_weight,omitempty"`                     // Emotion weight (default 1.0)
	EmoVec                      []float64 `json:"emo_vec,omitempty"`                        // Emotion vector [8 floats]
	EmoText                     string    `json:"emo_text,omitempty"`                       // Emotion description text
	EmoRandom                   bool      `json:"emo_random,omitempty"`                     // Random emotion
	MaxTextTokensPerSentence    int       `json:"max_text_tokens_per_sentence,omitempty"`   // Default 120
	// ğŸ”¥ æ–°å¢ï¼šæ”¯æŒç‹¬ç«‹çš„æƒ…æ„ŸéŸ³é¢‘è·¯å¾„å’Œæƒ…æ„Ÿå¼ºåº¦
	EmoAudioPath                *string   `json:"emo_audio_path,omitempty"`                 // Optional: separate emotion audio path
	EmoAlpha                    float64   `json:"emo_alpha,omitempty"`                      // Emotion strength (0.0-1.0)
}

// éŸ³é¢‘ä¸Šä¼ å“åº”ç»“æ„
type audioUploadResponse struct {
	ServerPath string `json:"server_path"`
	Filename   string `json:"filename"`
	Size       int64  `json:"size"`
	Status     string `json:"status"`
}

// vllmSynthesizeResponse represents the native API response format.
type vllmSynthesizeResponse struct {
	Audio      string `json:"audio,omitempty"`       // Base64 encoded audio
	AudioURL   string `json:"audio_url,omitempty"`   // URL to audio file
	DurationMs int    `json:"duration_ms,omitempty"` // Audio duration
	Success    bool   `json:"success,omitempty"`
	Message    string `json:"message,omitempty"`
}

// Synthesize generates speech using the index-tts-vllm API
func (c *VLLMClient) Synthesize(ctx context.Context, req SynthesisRequest) (io.ReadCloser, error) {
	c.logger.Info("Starting TTS synthesis with voice cloning",
		zap.String("text_preview", req.Text[:min(50, len(req.Text))]),
		zap.String("speaker_id", req.SpeakerID),
		zap.String("prompt_audio_url", req.PromptAudioURL),
	)

	// ğŸ”¥ ä¼˜å…ˆå°è¯•å¢å¼ºçš„éŸ³è‰²å…‹éš†æ¥å£
	if req.PromptAudioURL != "" {
		c.logger.Info("Attempting voice cloning with original audio",
			zap.String("audio_url", req.PromptAudioURL))

		audioResp, err := c.tryVoiceCloningWithUpload(ctx, req)
		if err != nil {
			c.logger.Warn("Voice cloning failed, falling back to standard TTS",
				zap.Error(err),
				zap.String("fallback_speaker", req.SpeakerID))
			// é™çº§åˆ°æ ‡å‡†TTS
			return c.tryIndexTTSV2Endpoint(ctx, req)
		}

		c.logger.Info("Voice cloning synthesis successful")
		return audioResp, nil
	}

	// æ²¡æœ‰åŸå§‹éŸ³é¢‘ï¼Œä½¿ç”¨æ ‡å‡†TTS
	c.logger.Info("Using standard TTS (no voice cloning)")
	return c.tryIndexTTSV2Endpoint(ctx, req)
}

// ğŸ”¥ æ ¸å¿ƒæ–°åŠŸèƒ½ï¼šéŸ³è‰²å…‹éš†ä¸éŸ³é¢‘ä¸Šä¼ 
func (c *VLLMClient) tryVoiceCloningWithUpload(ctx context.Context, req SynthesisRequest) (io.ReadCloser, error) {
	// æ­¥éª¤1ï¼šä¸Šä¼ åŸå§‹éŸ³é¢‘
	serverPath, err := c.uploadPromptAudio(ctx, req.PromptAudioURL)
	if err != nil {
		return nil, fmt.Errorf("failed to upload prompt audio: %w", err)
	}

	c.logger.Info("Audio uploaded successfully, starting voice cloning synthesis",
		zap.String("server_path", serverPath))

	// æ­¥éª¤2ï¼šä½¿ç”¨ä¸Šä¼ çš„éŸ³é¢‘è¿›è¡ŒéŸ³è‰²å…‹éš†
	return c.executeVoiceCloningRequest(ctx, req, serverPath)
}

// ä¸Šä¼ éŸ³é¢‘åˆ°TTSæœåŠ¡å™¨
func (c *VLLMClient) uploadPromptAudio(ctx context.Context, audioURL string) (string, error) {
	c.logger.Debug("Starting audio upload", zap.String("url", audioURL))

	// 1. ä¸‹è½½åŸéŸ³é¢‘æ–‡ä»¶
	resp, err := http.Get(audioURL)
	if err != nil {
		return "", fmt.Errorf("failed to download audio from %s: %w", audioURL, err)
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return "", fmt.Errorf("failed to download audio, status: %d", resp.StatusCode)
	}

	// 2. å‡†å¤‡multipartä¸Šä¼ 
	var buf bytes.Buffer
	writer := multipart.NewWriter(&buf)

	// ä»URLä¸­æå–æ–‡ä»¶åï¼Œæˆ–ä½¿ç”¨é»˜è®¤åç§°
	filename := "prompt.wav"
	if parsedName := filepath.Base(audioURL); parsedName != "" && parsedName != "/" && parsedName != "." {
		filename = parsedName
	}

	part, err := writer.CreateFormFile("file", filename)
	if err != nil {
		return "", fmt.Errorf("failed to create form file: %w", err)
	}

	// å¤åˆ¶éŸ³é¢‘æ•°æ®
	copySize, err := io.Copy(part, resp.Body)
	if err != nil {
		return "", fmt.Errorf("failed to copy audio data: %w", err)
	}

	if err := writer.Close(); err != nil {
		return "", fmt.Errorf("failed to close multipart writer: %w", err)
	}

	c.logger.Debug("Audio data prepared for upload",
		zap.Int64("size", copySize),
		zap.String("filename", filename))

	// 3. ä¸Šä¼ åˆ°TTSæœåŠ¡å™¨
	uploadURL := fmt.Sprintf("%s/upload_audio", c.baseURL)
	uploadReq, err := http.NewRequestWithContext(ctx, "POST", uploadURL, &buf)
	if err != nil {
		return "", fmt.Errorf("failed to create upload request: %w", err)
	}

	uploadReq.Header.Set("Content-Type", writer.FormDataContentType())

	// è®¾ç½®è¾ƒé•¿çš„è¶…æ—¶æ—¶é—´
	uploadClient := &http.Client{Timeout: 60 * time.Second}
	httpResp, err := uploadClient.Do(uploadReq)
	if err != nil {
		return "", fmt.Errorf("failed to upload audio: %w", err)
	}
	defer httpResp.Body.Close()

	// 4. å¤„ç†ä¸Šä¼ å“åº”
	if httpResp.StatusCode != http.StatusOK {
		body, _ := io.ReadAll(httpResp.Body)
		return "", fmt.Errorf("upload failed with status %d: %s", httpResp.StatusCode, string(body))
	}

	var result audioUploadResponse
	if err := json.NewDecoder(httpResp.Body).Decode(&result); err != nil {
		return "", fmt.Errorf("failed to decode upload response: %w", err)
	}

	if result.Status != "success" {
		return "", fmt.Errorf("upload unsuccessful: %s", result.Status)
	}

	c.logger.Info("Audio uploaded successfully",
		zap.String("server_path", result.ServerPath),
		zap.String("filename", result.Filename),
		zap.Int64("size", result.Size),
	)

	return result.ServerPath, nil
}

// æ‰§è¡ŒéŸ³è‰²å…‹éš†è¯·æ±‚
func (c *VLLMClient) executeVoiceCloningRequest(ctx context.Context, req SynthesisRequest, serverPath string) (io.ReadCloser, error) {
	// æ„å»ºéŸ³è‰²å…‹éš†è¯·æ±‚
	v2Req := indexTTSV2Request{
		Text:                     req.Text,
		SpkAudioPath:             serverPath,        // éŸ³è‰²å‚è€ƒ
		MaxTextTokensPerSentence: 120,
		EmoAudioPath:             &serverPath,       // ğŸ”¥ æƒ…æ„Ÿå‚è€ƒï¼ˆåŒä¸€æ–‡ä»¶ï¼‰
		EmoAlpha:                 0.8,               // ğŸ”¥ æƒ…æ„Ÿå¼ºåº¦
	}

	// ä¼˜å…ˆå°è¯•å¢å¼ºçš„éŸ³è‰²å…‹éš†æ¥å£
	return c.tryVoiceCloningEndpoint(ctx, v2Req)
}

// å°è¯•æ–°çš„éŸ³è‰²å…‹éš†æ¥å£
func (c *VLLMClient) tryVoiceCloningEndpoint(ctx context.Context, req indexTTSV2Request) (io.ReadCloser, error) {
	bodyBytes, err := json.Marshal(req)
	if err != nil {
		return nil, fmt.Errorf("failed to marshal voice cloning request: %w", err)
	}

	url := fmt.Sprintf("%s/tts_url_with_cloning", c.baseURL)
	httpReq, err := http.NewRequestWithContext(ctx, "POST", url, bytes.NewReader(bodyBytes))
	if err != nil {
		return nil, fmt.Errorf("failed to create voice cloning request: %w", err)
	}

	c.setHeaders(httpReq)

	c.logger.Debug("Calling voice cloning endpoint",
		zap.String("url", url),
		zap.String("spk_audio_path", req.SpkAudioPath),
		zap.String("emo_audio_path", *req.EmoAudioPath),
		zap.Float64("emo_alpha", req.EmoAlpha))

	resp, err := c.client.Do(httpReq)
	if err != nil {
		return nil, fmt.Errorf("voice cloning request failed: %w", err)
	}

	if resp.StatusCode != http.StatusOK {
		resp.Body.Close()
		body, _ := io.ReadAll(resp.Body)
		return nil, fmt.Errorf("voice cloning endpoint returned status %d: %s", resp.StatusCode, string(body))
	}

	c.logger.Info("Voice cloning endpoint success")
	return resp.Body, nil
}

// é™çº§åˆ°åŸæœ‰çš„IndexTTS v2æ¥å£
func (c *VLLMClient) tryIndexTTSV2Endpoint(ctx context.Context, req SynthesisRequest) (io.ReadCloser, error) {
	// ä½¿ç”¨é¢„è®¾éŸ³è‰²
	spkAudioPath := c.getFallbackSpeaker(req.SpeakerID)

	v2Req := indexTTSV2Request{
		Text:                     req.Text,
		SpkAudioPath:             spkAudioPath,
		EmoControlMethod:         0, // æƒ…æ„Ÿä¸éŸ³è‰²å‚è€ƒéŸ³é¢‘ç›¸åŒ
		MaxTextTokensPerSentence: 120,
	}

	bodyBytes, err := json.Marshal(v2Req)
	if err != nil {
		return nil, fmt.Errorf("failed to marshal IndexTTS v2 request: %w", err)
	}

	url := fmt.Sprintf("%s/tts_url", c.baseURL)
	httpReq, err := http.NewRequestWithContext(ctx, "POST", url, bytes.NewReader(bodyBytes))
	if err != nil {
		return nil, fmt.Errorf("failed to create request: %w", err)
	}

	c.setHeaders(httpReq)

	c.logger.Debug("Trying IndexTTS v2 /tts_url (fallback)",
		zap.String("url", url),
		zap.String("spk_audio_path", spkAudioPath))

	resp, err := c.client.Do(httpReq)
	if err != nil {
		return nil, fmt.Errorf("IndexTTS v2 request failed: %w", err)
	}

	if resp.StatusCode != http.StatusOK {
		resp.Body.Close()
		body, _ := io.ReadAll(resp.Body)
		return nil, fmt.Errorf("IndexTTS v2 returned status %d: %s", resp.StatusCode, string(body))
	}

	c.logger.Info("IndexTTS v2 /tts_url fallback success")
	return resp.Body, nil
}

// æ™ºèƒ½é¢„è®¾éŸ³è‰²é€‰æ‹©
func (c *VLLMClient) getFallbackSpeaker(speakerID string) string {
	// ğŸ”§ æ ¹æ®ä½ çš„å®é™…è·¯å¾„è°ƒæ•´
	speakerMapping := map[string]string{
		"default":      "/root/index-tts-vllm/examples/voice_01.wav",
		"male_young":   "/root/index-tts-vllm/examples/voice_01.wav",
		"female_young": "/root/index-tts-vllm/examples/voice_01.wav", // ä½ å¯ä»¥è°ƒæ•´ä¸ºvoice_02.wav
		"male_mature":  "/root/index-tts-vllm/examples/voice_01.wav",
		"female_mature": "/root/index-tts-vllm/examples/voice_01.wav",
		"speaker_1":    "/root/index-tts-vllm/examples/voice_01.wav",
		"speaker_2":    "/root/index-tts-vllm/examples/voice_01.wav",
		"speaker_3":    "/root/index-tts-vllm/examples/voice_01.wav",
	}

	if path, exists := speakerMapping[speakerID]; exists {
		return path
	}
	return speakerMapping["default"]
}

// è®¾ç½®HTTPè¯·æ±‚å¤´
func (c *VLLMClient) setHeaders(req *http.Request) {
	req.Header.Set("Content-Type", "application/json")
	if c.apiKey != "" {
		req.Header.Set("Authorization", fmt.Sprintf("Bearer %s", c.apiKey))
	}
}

// å·¥å…·å‡½æ•°ï¼šè¿”å›è¾ƒå°å€¼
func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}