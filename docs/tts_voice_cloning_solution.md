# TTSéŸ³è‰²å…‹éš†å®Œæ•´è§£å†³æ–¹æ¡ˆ

åŸºäº `index-tts-vllm` æœåŠ¡çš„APIåˆ†æ

## ğŸ” å…³é”®å‘ç°

### IndexTTS V2 API èƒ½åŠ›åˆ†æ

**æ¥å£**: `POST /tts_url`

**å…³é”®å‚æ•°**:
- `spk_audio_path`: éŸ³è‰²å‚è€ƒéŸ³é¢‘è·¯å¾„ âœ…
- `emo_control_method`: æƒ…æ„Ÿæ§åˆ¶æ–¹å¼ âœ…
- `emo_ref_path`: æƒ…æ„Ÿå‚è€ƒéŸ³é¢‘è·¯å¾„ âœ…
- `emo_weight`: æƒ…æ„Ÿæƒé‡æ§åˆ¶ âœ…
- `emo_vec`: 8ç»´æƒ…æ„Ÿå‘é‡æ§åˆ¶ âœ…
- `emo_text`: æƒ…æ„Ÿæ–‡æœ¬æè¿°æ§åˆ¶ âœ…

### ğŸ¯ é—®é¢˜æ ¹æœ¬åŸå› ç¡®è®¤

**æˆ‘ä»¬å½“å‰çš„å®ç°é—®é¢˜**:

1. **éŸ³è‰²å…‹éš†å¤±æ•ˆ**:
   ```go
   // å½“å‰ä»£ç  - ç¡¬ç¼–ç é¢„è®¾éŸ³è‰²
   speakerMapping := map[string]string{
       "default": "/root/index-tts-vllm/examples/voice_01.wav",
       // ...
   }
   spkAudioPath := speakerMapping[req.SpeakerID] // âŒ æ²¡ç”¨åŸéŸ³é¢‘
   ```

2. **æƒ…æ„Ÿå‚è€ƒç¼ºå¤±**:
   ```go
   v2Req := indexTTSV2Request{
       EmoControlMethod: 0, // è™½ç„¶è®¾ä¸º0ï¼Œä½†spk_audio_pathæœ¬èº«ä¸æ˜¯åŸéŸ³é¢‘
       // æ²¡æœ‰è®¾ç½® emo_ref_path
   }
   ```

## ğŸš€ å®Œæ•´è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆ: éŸ³é¢‘ä¸Šä¼  + å®Œæ•´æƒ…æ„Ÿæ§åˆ¶

**æ ¸å¿ƒæ€è·¯**:
1. å°†æå–çš„åŸå§‹éŸ³é¢‘ä¸Šä¼ åˆ°TTSæœåŠ¡å™¨
2. åŒæ—¶ç”¨ä½œéŸ³è‰²å’Œæƒ…æ„Ÿå‚è€ƒ
3. æ·»åŠ å¤šç§æƒ…æ„Ÿæ§åˆ¶é™çº§æœºåˆ¶

### ç¬¬ä¸€æ­¥: éŸ³é¢‘ä¸Šä¼ åŠŸèƒ½

```go
// 1. æ·»åŠ éŸ³é¢‘ä¸Šä¼ æ¥å£
func (c *VLLMClient) uploadPromptAudio(ctx context.Context, audioURL string) (string, error) {
    // ä¸‹è½½éŸ³é¢‘æ–‡ä»¶
    resp, err := http.Get(audioURL)
    if err != nil {
        return "", fmt.Errorf("failed to download audio: %w", err)
    }
    defer resp.Body.Close()

    // ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
    fileName := fmt.Sprintf("prompt_%d.wav", time.Now().UnixNano())
    serverPath := fmt.Sprintf("/tmp/uploaded_prompts/%s", fileName)

    // ä¸Šä¼ åˆ°æœåŠ¡å™¨ (é€šè¿‡é¢å¤–çš„ä¸Šä¼ æ¥å£æˆ–ç›´æ¥æ–‡ä»¶ä¼ è¾“)
    // è¿™é‡Œéœ€è¦æ ¹æ®å®é™…éƒ¨ç½²æƒ…å†µå®ç°
    // å¯èƒ½éœ€è¦æ·»åŠ ä¸€ä¸ªæ–‡ä»¶ä¸Šä¼ ç«¯ç‚¹åˆ° api_server_v2.py

    return serverPath, nil
}
```

### ç¬¬äºŒæ­¥: å®Œæ•´çš„VLLMå®¢æˆ·ç«¯æ”¹é€ 

```go
// æ›´æ–° indexTTSV2Request ç»“æ„
type indexTTSV2Request struct {
    Text                     string    `json:"text"`
    SpkAudioPath             string    `json:"spk_audio_path"`
    EmoControlMethod         int       `json:"emo_control_method"`
    EmoRefPath               *string   `json:"emo_ref_path,omitempty"`      // æ–°å¢
    EmoWeight                *float64  `json:"emo_weight,omitempty"`        // æ–°å¢
    EmoVec                   []float64 `json:"emo_vec,omitempty"`           // æ–°å¢
    EmoText                  *string   `json:"emo_text,omitempty"`          // æ–°å¢
    MaxTextTokensPerSentence int       `json:"max_text_tokens_per_sentence"`
}

// æ”¹é€ åˆæˆæ–¹æ³•
func (c *VLLMClient) tryIndexTTSV2Endpoint(ctx context.Context, req SynthesisRequest) (io.ReadCloser, error) {
    var spkAudioPath string

    // ğŸ”¥ æ ¸å¿ƒä¿®å¤: ä¸Šä¼ åŸå§‹éŸ³é¢‘
    if req.PromptAudioURL != "" {
        uploaded, err := c.uploadPromptAudio(ctx, req.PromptAudioURL)
        if err != nil {
            c.logger.Warn("Failed to upload prompt audio, using fallback",
                zap.String("url", req.PromptAudioURL),
                zap.Error(err))
            spkAudioPath = c.getFallbackSpeaker(req.SpeakerID)
        } else {
            spkAudioPath = uploaded
            c.logger.Info("Successfully uploaded prompt audio",
                zap.String("server_path", spkAudioPath))
        }
    } else {
        spkAudioPath = c.getFallbackSpeaker(req.SpeakerID)
    }

    // ğŸµ æƒ…æ„Ÿæ§åˆ¶ç­–ç•¥
    v2Req := c.buildOptimalRequest(req.Text, spkAudioPath, req)

    return c.executeRequest(ctx, v2Req)
}

// æ™ºèƒ½æƒ…æ„Ÿæ§åˆ¶ç­–ç•¥
func (c *VLLMClient) buildOptimalRequest(text, spkAudioPath string, req SynthesisRequest) indexTTSV2Request {
    baseReq := indexTTSV2Request{
        Text:                     text,
        SpkAudioPath:             spkAudioPath,
        MaxTextTokensPerSentence: 120,
    }

    // ç­–ç•¥1: ä¼˜å…ˆä½¿ç”¨åŸéŸ³é¢‘ä½œä¸ºæƒ…æ„Ÿå’ŒéŸ³è‰²å‚è€ƒ
    if req.PromptAudioURL != "" && spkAudioPath != "" {
        baseReq.EmoControlMethod = 0 // æƒ…æ„Ÿä¸éŸ³è‰²å‚è€ƒéŸ³é¢‘ç›¸åŒ
        return baseReq
    }

    // ç­–ç•¥2: å¦‚æœæœ‰æƒ…æ„Ÿåå¥½ï¼Œä½¿ç”¨æƒ…æ„Ÿå‘é‡
    if emotionVec := c.inferEmotionFromContext(req); emotionVec != nil {
        baseReq.EmoControlMethod = 2
        baseReq.EmoVec = emotionVec
        return baseReq
    }

    // ç­–ç•¥3: é»˜è®¤ä½¿ç”¨éŸ³è‰²éŸ³é¢‘çš„æƒ…æ„Ÿ
    baseReq.EmoControlMethod = 0
    return baseReq
}

// æƒ…æ„Ÿæ¨ç† (åŸºäºæ–‡æœ¬å†…å®¹)
func (c *VLLMClient) inferEmotionFromContext(req SynthesisRequest) []float64 {
    // ç®€å•çš„æƒ…æ„Ÿæ¨ç†é€»è¾‘
    // ["å–œ", "æ€’", "å“€", "æƒ§", "åŒæ¶", "ä½è½", "æƒŠå–œ", "å¹³é™"]

    text := strings.ToLower(req.Text)

    // æ‚²ä¼¤æƒ…æ„Ÿ
    if strings.Contains(text, "sad") || strings.Contains(text, "cry") ||
       strings.Contains(text, "æ‚²") || strings.Contains(text, "å“­") {
        return []float64{0, 0, 0.8, 0, 0, 0.3, 0, 0} // å“€+ä½è½
    }

    // æ„¤æ€’æƒ…æ„Ÿ
    if strings.Contains(text, "angry") || strings.Contains(text, "mad") ||
       strings.Contains(text, "æ€’") || strings.Contains(text, "ç”Ÿæ°”") {
        return []float64{0, 0.9, 0, 0, 0.2, 0, 0, 0} // æ€’+åŒæ¶
    }

    // å–œæ‚¦æƒ…æ„Ÿ
    if strings.Contains(text, "happy") || strings.Contains(text, "joy") ||
       strings.Contains(text, "å¼€å¿ƒ") || strings.Contains(text, "é«˜å…´") {
        return []float64{0.8, 0, 0, 0, 0, 0, 0.3, 0} // å–œ+æƒŠå–œ
    }

    // é»˜è®¤å¹³é™
    return []float64{0, 0, 0, 0, 0, 0, 0, 0.8} // å¹³é™
}
```

### ç¬¬ä¸‰æ­¥: éŸ³é¢‘ä¸Šä¼ æœåŠ¡ç«¯æ”¯æŒ

**éœ€è¦åœ¨ `api_server_v2.py` ä¸­æ·»åŠ æ–‡ä»¶ä¸Šä¼ ç«¯ç‚¹**:

```python
from fastapi import FastAPI, UploadFile, File
import shutil
import os

app = FastAPI()

@app.post("/upload_audio")
async def upload_audio(file: UploadFile = File(...)):
    """ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ä¾›TTSä½¿ç”¨"""
    upload_dir = "/tmp/uploaded_prompts"
    os.makedirs(upload_dir, exist_ok=True)

    file_path = os.path.join(upload_dir, file.filename)

    with open(file_path, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)

    return {"server_path": file_path}
```

### ç¬¬å››æ­¥: å®¢æˆ·ç«¯éŸ³é¢‘ä¸Šä¼ å®ç°

```go
func (c *VLLMClient) uploadPromptAudio(ctx context.Context, audioURL string) (string, error) {
    // 1. ä¸‹è½½éŸ³é¢‘
    resp, err := http.Get(audioURL)
    if err != nil {
        return "", err
    }
    defer resp.Body.Close()

    // 2. å‡†å¤‡ä¸Šä¼ 
    var buf bytes.Buffer
    writer := multipart.NewWriter(&buf)

    part, err := writer.CreateFormFile("file", "prompt.wav")
    if err != nil {
        return "", err
    }

    _, err = io.Copy(part, resp.Body)
    if err != nil {
        return "", err
    }
    writer.Close()

    // 3. ä¸Šä¼ åˆ°æœåŠ¡å™¨
    uploadURL := fmt.Sprintf("%s/upload_audio", c.baseURL)
    req, err := http.NewRequestWithContext(ctx, "POST", uploadURL, &buf)
    if err != nil {
        return "", err
    }
    req.Header.Set("Content-Type", writer.FormDataContentType())

    httpResp, err := c.httpClient.Do(req)
    if err != nil {
        return "", err
    }
    defer httpResp.Body.Close()

    var result struct {
        ServerPath string `json:"server_path"`
    }

    if err := json.NewDecoder(httpResp.Body).Decode(&result); err != nil {
        return "", err
    }

    return result.ServerPath, nil
}
```

## ğŸ¯ å®æ–½ä¼˜å…ˆçº§

### Phase 1: æœ€å°å¯è¡Œä¿®å¤ (ä»Šå¤©)
1. âœ… ä¿®æ”¹VLLMå®¢æˆ·ç«¯ä½¿ç”¨ `emo_control_method=0`
2. âœ… å®ç°éŸ³é¢‘ä¸Šä¼ åŠŸèƒ½
3. âœ… æ·»åŠ ä¸Šä¼ å¤±è´¥é™çº§æœºåˆ¶

### Phase 2: æƒ…æ„Ÿå¢å¼º (æœ¬å‘¨)
1. ğŸ”„ æ·»åŠ æƒ…æ„Ÿå‘é‡æ¨ç†
2. ğŸ”„ æ”¯æŒå¤šç§æƒ…æ„Ÿæ§åˆ¶æ¨¡å¼
3. ğŸ”„ ä¼˜åŒ–æç¤ºéŸ³é¢‘ç‰‡æ®µé€‰æ‹©

### Phase 3: é«˜çº§ä¼˜åŒ– (ä¸‹å‘¨)
1. ğŸ”® éŸ³é¢‘è´¨é‡æ£€æµ‹å’Œå¢å¼º
2. ğŸ”® æƒ…æ„Ÿå¼ºåº¦è‡ªé€‚åº”è°ƒèŠ‚
3. ğŸ”® éŸ³è‰²ç›¸ä¼¼åº¦è¯„ä¼°

## ğŸ“ˆ é¢„æœŸæ•ˆæœ

| æŒ‡æ ‡ | å½“å‰ | Phase 1å | Phase 2å | Phase 3å |
|------|------|-----------|-----------|-----------|
| éŸ³è‰²ç›¸ä¼¼åº¦ | 30% | 70% | 80% | 85%+ |
| æƒ…æ„Ÿä¸€è‡´æ€§ | 20% | 60% | 75% | 80%+ |
| æ•´ä½“è´¨é‡ | â­â­ | â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ |

## ğŸ”§ ç«‹å³å¯æ‰§è¡Œçš„æœ€å°ä¿®å¤

**å¦‚æœæœåŠ¡å™¨ä¸æ”¯æŒæ–‡ä»¶ä¸Šä¼ ï¼Œå¯ä»¥å…ˆè¿™æ ·æ”¹è¿›**:

```go
// ä¸´æ—¶è§£å†³æ–¹æ¡ˆ: æ™ºèƒ½é¢„è®¾éŸ³è‰²é€‰æ‹©
func (c *VLLMClient) getIntelligentSpeaker(req SynthesisRequest) string {
    // åŸºäºä»»åŠ¡ä¿¡æ¯æ™ºèƒ½é€‰æ‹©é¢„è®¾éŸ³è‰²
    // å¯ä»¥æ ¹æ®è¯­è¨€ã€æ€§åˆ«ã€å¹´é¾„ç­‰ç‰¹å¾é€‰æ‹©

    speakerMapping := map[string]string{
        "zh_male_young":   "/root/index-tts-vllm/examples/voice_01.wav",
        "zh_female_young": "/root/index-tts-vllm/examples/voice_02.wav",
        "zh_male_mature":  "/root/index-tts-vllm/examples/voice_04.wav",
        "zh_female_mature": "/root/index-tts-vllm/examples/voice_05.wav",
    }

    // TODO: åŸºäºåŸéŸ³é¢‘åˆ†æé€‰æ‹©æœ€åŒ¹é…çš„é¢„è®¾éŸ³è‰²
    return speakerMapping["zh_male_young"] // ä¸´æ—¶
}

// åŒæ—¶æ”¹è¿›æƒ…æ„Ÿæ§åˆ¶
v2Req := indexTTSV2Request{
    Text:                     req.Text,
    SpkAudioPath:             c.getIntelligentSpeaker(req),
    EmoControlMethod:         2, // ä½¿ç”¨æƒ…æ„Ÿå‘é‡
    EmoVec:                   c.inferEmotionFromContext(req), // æ™ºèƒ½æƒ…æ„Ÿæ¨ç†
    MaxTextTokensPerSentence: 120,
}
```

è¿™æ ·å³ä½¿ä¸èƒ½ç«‹å³å®ç°éŸ³é¢‘ä¸Šä¼ ï¼Œä¹Ÿèƒ½æ˜¾è‘—æ”¹å–„éŸ³è‰²é€‰æ‹©å’Œæƒ…æ„Ÿè¡¨è¾¾ï¼