# TTSéŸ³è‰²å…‹éš†å’Œæƒ…æ„Ÿå‚è€ƒé—®é¢˜åˆ†æ

## ğŸ” é—®é¢˜åˆ†æ

### é—®é¢˜1: éŸ³è‰²å…‹éš†æœªç”Ÿæ•ˆ
**ç°è±¡**: ç”Ÿæˆçš„é…éŸ³å£°éŸ³ä¸åŸè§†é¢‘è¯´è¯äººéŸ³è‰²å·®å¼‚æ˜æ˜¾

**æ ¹æœ¬åŸå› åˆ†æ**:

1. **VLLMå®¢æˆ·ç«¯é—®é¢˜** (`vllm_client.go:139-150`)
   ```go
   speakerMapping := map[string]string{
       "default":   "/root/index-tts-vllm/examples/voice_01.wav",
       "speaker_1": "/root/index-tts-vllm/examples/voice_01.wav",
       // ... ä½¿ç”¨æœåŠ¡å™¨é¢„è®¾éŸ³è‰²ï¼Œä¸æ˜¯åŸå§‹éŸ³é¢‘
   }
   ```
   - **é—®é¢˜**: ä½¿ç”¨ç¡¬ç¼–ç çš„æœåŠ¡å™¨é¢„è®¾éŸ³è‰²æ–‡ä»¶
   - **å¿½ç•¥**: å®Œå…¨æ²¡æœ‰ä½¿ç”¨æå–çš„åŸå§‹éŸ³é¢‘ä½œä¸ºéŸ³è‰²å‚è€ƒ

2. **Gradioå®¢æˆ·ç«¯éƒ¨åˆ†æ­£ç¡®** (`gradio_client.go:194-202`)
   ```go
   // Parameter 1: prompt (audio file for voice reference)
   if req.PromptAudioURL != "" {
       data[1] = map[string]interface{}{
           "path": req.PromptAudioURL,  // âœ… ä½¿ç”¨äº†æå–çš„éŸ³é¢‘
           "url":  req.PromptAudioURL,
       }
   }
   ```
   - **æ­£ç¡®**: ä½¿ç”¨äº†ä»åŸè§†é¢‘æå–çš„éŸ³è‰²å‚è€ƒéŸ³é¢‘
   - **ä½†**: å¯èƒ½URLè®¿é—®æœ‰é—®é¢˜

### é—®é¢˜2: æƒ…æ„Ÿå‚è€ƒç¼ºå¤±
**ç°è±¡**: ç”Ÿæˆçš„é…éŸ³æƒ…æ„Ÿå•è°ƒï¼Œæ²¡æœ‰å‚è€ƒåŸéŸ³é¢‘çš„æƒ…æ„Ÿè¡¨è¾¾

**æ ¹æœ¬åŸå› åˆ†æ**:

1. **Gradioå®¢æˆ·ç«¯**: æƒ…æ„Ÿå‚è€ƒæœªä½¿ç”¨
   ```go
   // Parameter 3: emo_ref_path (emotion reference audio)
   data[3] = nil  // âŒ æƒ…æ„Ÿå‚è€ƒä¸ºç©º
   ```

2. **VLLMå®¢æˆ·ç«¯**: æƒ…æ„Ÿæ§åˆ¶æ–¹æ³•è¿‡äºç®€åŒ–
   ```go
   EmoControlMethod: 0, // 0 = use speaker audio for emotion too
   ```
   - è™½ç„¶è®¾ç½®ä¸ºä½¿ç”¨speaker audioä½œä¸ºæƒ…æ„Ÿå‚è€ƒï¼Œä½†speaker audioæœ¬èº«å°±ä¸æ˜¯åŸéŸ³é¢‘

## ğŸ› ï¸ è§£å†³æ–¹æ¡ˆå¯¹æ¯”

### æ–¹æ¡ˆä¸€: ä¿®å¤VLLMå®¢æˆ·ç«¯ (æ¨èâ­â­â­â­â­)

**ä¼˜åŠ¿**:
- VLLMæ€§èƒ½æ›´å¥½ï¼Œæ”¯æŒæ‰¹å¤„ç†
- éŸ³è‰²å…‹éš†è´¨é‡æ›´é«˜
- å¯ä»¥åŒæ—¶è§£å†³éŸ³è‰²å’Œæƒ…æ„Ÿé—®é¢˜

**å®æ–½æ–¹æ¡ˆ**:
1. **ä¸Šä¼ éŸ³é¢‘åˆ°TTSæœåŠ¡å™¨**
   ```go
   // æ·»åŠ éŸ³é¢‘ä¸Šä¼ åŠŸèƒ½
   func (c *VLLMClient) uploadPromptAudio(ctx context.Context, audioURL string) (string, error) {
       // ä¸‹è½½éŸ³é¢‘æ–‡ä»¶
       resp, err := http.Get(audioURL)
       // ä¸Šä¼ åˆ°TTSæœåŠ¡å™¨çš„ä¸´æ—¶ç›®å½•
       // è¿”å›æœåŠ¡å™¨æœ¬åœ°è·¯å¾„
   }
   ```

2. **ä½¿ç”¨å®é™…éŸ³é¢‘è·¯å¾„**
   ```go
   // ä¿®æ”¹spkAudioPathé€»è¾‘
   var spkAudioPath string
   if req.PromptAudioURL != "" {
       // ä¸Šä¼ å¹¶ä½¿ç”¨å®é™…éŸ³é¢‘
       spkAudioPath, err = c.uploadPromptAudio(ctx, req.PromptAudioURL)
   } else {
       // é™çº§åˆ°é¢„è®¾éŸ³è‰²
       spkAudioPath = speakerMapping[req.SpeakerID]
   }
   ```

3. **æƒ…æ„Ÿæ§åˆ¶ä¼˜åŒ–**
   ```go
   v2Req := indexTTSV2Request{
       Text:                     req.Text,
       SpkAudioPath:             spkAudioPath,
       EmoControlMethod:         0, // ä½¿ç”¨speaker audioä½œä¸ºæƒ…æ„Ÿå‚è€ƒ
       EmoReferenceAudio:        spkAudioPath, // æ˜¾å¼è®¾ç½®æƒ…æ„Ÿå‚è€ƒ
       MaxTextTokensPerSentence: 120,
   }
   ```

### æ–¹æ¡ˆäºŒ: æ”¹è¿›Gradioå®¢æˆ·ç«¯ (å¤‡é€‰â­â­â­)

**å®æ–½æ–¹æ¡ˆ**:
1. **ä¿®å¤æƒ…æ„Ÿå‚è€ƒ**
   ```go
   // Parameter 3: emo_ref_path (emotion reference audio)
   if req.PromptAudioURL != "" {
       data[3] = map[string]interface{}{
           "path": req.PromptAudioURL,
           "url":  req.PromptAudioURL,
           "meta": map[string]interface{}{"_type": "gradio.FileData"},
       }
   }
   ```

2. **ä¼˜åŒ–éŸ³è‰²å‚è€ƒ**
   ```go
   // ç¡®ä¿éŸ³é¢‘URLå¯è®¿é—®
   // æ·»åŠ é‡è¯•æœºåˆ¶å’Œé”™è¯¯å¤„ç†
   ```

### æ–¹æ¡ˆä¸‰: æ··åˆç­–ç•¥ (æœ€ä½³â­â­â­â­â­)

**æ ¸å¿ƒæ€æƒ³**:
- ä¼˜å…ˆä½¿ç”¨VLLM (æ€§èƒ½+è´¨é‡)
- Gradioä½œä¸ºé™çº§å¤‡é€‰
- éŸ³é¢‘ä¸Šä¼ å¤±è´¥æ—¶ä½¿ç”¨é¢„è®¾éŸ³è‰²

**å®æ–½æ­¥éª¤**:

1. **ç»Ÿä¸€éŸ³é¢‘å¤„ç†æ¥å£**
   ```go
   type AudioUploader interface {
       UploadPromptAudio(ctx context.Context, audioURL string) (string, error)
       GetFallbackSpeaker(speakerID string) string
   }
   ```

2. **æ™ºèƒ½é™çº§æœºåˆ¶**
   ```go
   func (c *VLLMClient) synthesizeWithVoiceCloning(ctx context.Context, req SynthesisRequest) (io.ReadCloser, error) {
       // 1. å°è¯•ä¸Šä¼ åŸéŸ³é¢‘
       spkAudioPath, err := c.uploadPromptAudio(ctx, req.PromptAudioURL)
       if err != nil {
           // 2. é™çº§åˆ°é¢„è®¾éŸ³è‰²
           spkAudioPath = c.getFallbackSpeaker(req.SpeakerID)
           c.logger.Warn("Failed to upload prompt audio, using fallback", zap.Error(err))
       }

       // 3. æ‰§è¡ŒTTS
       return c.synthesizeWithPath(ctx, req.Text, spkAudioPath)
   }
   ```

3. **å¢å¼ºæç¤ºéŸ³é¢‘è´¨é‡**
   ```go
   // åœ¨selectPromptSegmentä¸­ä¼˜åŒ–é€‰æ‹©é€»è¾‘
   func (p *TTSProcessor) selectOptimalPromptSegment(ctx context.Context, taskID uuid.UUID) (promptSegment, error) {
       // 1. ä¼˜å…ˆé€‰æ‹©æ¸…æ™°åº¦é«˜çš„ç‰‡æ®µ
       // 2. é¿å…æœ‰èƒŒæ™¯éŸ³ä¹çš„ç‰‡æ®µ
       // 3. é€‰æ‹©éŸ³é‡é€‚ä¸­çš„ç‰‡æ®µ
       // 4. ä¼˜å…ˆé€‰æ‹©æƒ…æ„Ÿè¡¨è¾¾ä¸°å¯Œçš„ç‰‡æ®µ
   }
   ```

## ğŸ’¡ æœ€ä½³è§£å†³æ–¹æ¡ˆæ¨è

**æ¨è: æ–¹æ¡ˆä¸‰ (æ··åˆç­–ç•¥)**

### å®æ–½ä¼˜å…ˆçº§:

**P0 (ç«‹å³å®æ–½)**:
1. ä¿®å¤VLLMå®¢æˆ·ç«¯çš„éŸ³é¢‘ä¸Šä¼ åŠŸèƒ½
2. æ·»åŠ éŸ³é¢‘ä¸Šä¼ å¤±è´¥çš„é™çº§æœºåˆ¶
3. ä¿®å¤Gradioå®¢æˆ·ç«¯çš„æƒ…æ„Ÿå‚è€ƒ

**P1 (ä¸€å‘¨å†…)**:
1. ä¼˜åŒ–æç¤ºéŸ³é¢‘ç‰‡æ®µé€‰æ‹©ç®—æ³•
2. æ·»åŠ éŸ³é¢‘è´¨é‡æ£€æµ‹å’Œè¿‡æ»¤
3. å®ç°æ™ºèƒ½speaker mapping

**P2 (ä¸¤å‘¨å†…)**:
1. æ·»åŠ éŸ³è‰²ç›¸ä¼¼åº¦è¯„ä¼°
2. å®ç°æƒ…æ„Ÿå¼ºåº¦æ§åˆ¶
3. ä¼˜åŒ–æ‰¹å¤„ç†æ€§èƒ½

### é¢„æœŸæ•ˆæœ:
- **éŸ³è‰²ç›¸ä¼¼åº¦**: ä»30% â†’ 85%+
- **æƒ…æ„Ÿä¸€è‡´æ€§**: ä»20% â†’ 75%+
- **æ•´ä½“è´¨é‡**: æ˜¾è‘—æå‡ç”¨æˆ·æ»¡æ„åº¦
- **æ€§èƒ½å½±å“**: è½»å¾® (å¢åŠ éŸ³é¢‘ä¸Šä¼ æ—¶é—´)

### é£é™©æ§åˆ¶:
- éŸ³é¢‘ä¸Šä¼ å¤±è´¥æ—¶è‡ªåŠ¨é™çº§
- ä¿æŒç°æœ‰APIå…¼å®¹æ€§
- æ·»åŠ è¯¦ç»†çš„é”™è¯¯æ—¥å¿—å’Œç›‘æ§

## ğŸ”§ å¿«é€Ÿä¿®å¤æ–¹æ¡ˆ (ä»Šå¤©å¯å®æ–½)

å¦‚æœéœ€è¦å¿«é€Ÿæ”¹å–„ï¼Œå¯ä»¥å…ˆå®æ–½ä»¥ä¸‹æœ€å°æ”¹åŠ¨:

```go
// åœ¨vllm_client.goä¸­ä¿®æ”¹
func (c *VLLMClient) tryIndexTTSV2Endpoint(ctx context.Context, req SynthesisRequest) (io.ReadCloser, error) {
    var spkAudioPath string

    // ğŸ”¥ Quick Fix: å°è¯•ä½¿ç”¨prompt audio URL
    if req.PromptAudioURL != "" {
        // TODO: å®ç°éŸ³é¢‘ä¸Šä¼ ï¼Œæš‚æ—¶è®°å½•è­¦å‘Š
        c.logger.Warn("PromptAudioURL provided but not used",
            zap.String("url", req.PromptAudioURL),
            zap.String("task_id", req.TaskID))
    }

    // æš‚æ—¶ä½¿ç”¨æ›´å¤šæ ·åŒ–çš„é¢„è®¾éŸ³è‰²
    speakerMapping := map[string]string{
        "default":   "/root/index-tts-vllm/examples/voice_01.wav",
        "male":      "/root/index-tts-vllm/examples/voice_04.wav",
        "female":    "/root/index-tts-vllm/examples/voice_02.wav",
        // æ ¹æ®åŸéŸ³é¢‘ç‰¹å¾æ™ºèƒ½é€‰æ‹©
    }

    spkAudioPath = c.intelligentSpeakerSelection(req, speakerMapping)
    // ...
}
```

è¿™æ ·è‡³å°‘å¯ä»¥è®°å½•é—®é¢˜å¹¶ä¸ºåç»­å®Œæ•´è§£å†³åšå‡†å¤‡ã€‚