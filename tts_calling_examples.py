# TTSè°ƒç”¨éƒ¨åˆ†çš„å…·ä½“è°ƒæ•´ç¤ºä¾‹

# ============================================
# ä½ç½®ï¼šapi_server_v2.py ç¬¬165è¡Œå·¦å³
# å‡½æ•°ï¼štts_inference_same_audio_ref()
# ============================================

async def tts_inference_same_audio_ref(text: str, spk_audio_path: str, emo_alpha: float, max_tokens: int):
    """ä½¿ç”¨åŒä¸€éŸ³é¢‘æ–‡ä»¶ä½œä¸ºéŸ³è‰²å’Œæƒ…æ„Ÿå‚è€ƒ"""
    try:
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        output_filename = f"tts_output_{int(time.time() * 1000)}.wav"
        output_path = f"/tmp/{output_filename}"

        # ğŸ”¥ è¿™é‡Œéœ€è¦æ ¹æ®ä½ çš„å®é™…TTSæ¨¡å‹è°ƒç”¨æ–¹å¼è¿›è¡Œè°ƒæ•´ ğŸ”¥
        # ============================================
        # æ–¹æ¡ˆAï¼šæ ‡å‡†IndexTTS 2.0è°ƒç”¨ï¼ˆæ¨èï¼‰
        # ============================================
        if hasattr(tts_model, 'infer'):
            # å®˜æ–¹IndexTTS 2.0 APIè°ƒç”¨æ–¹å¼
            result = tts_model.infer(
                spk_audio_prompt=spk_audio_path,    # éŸ³è‰²å‚è€ƒ
                emo_audio_prompt=spk_audio_path,    # æƒ…æ„Ÿå‚è€ƒï¼ˆåŒä¸€æ–‡ä»¶ï¼‰
                emo_alpha=emo_alpha,               # æƒ…æ„Ÿå¼ºåº¦
                text=text,
                output_path=output_path,
                max_text_tokens_per_sentence=max_tokens,
                verbose=True  # å¯é€‰ï¼šæ˜¾ç¤ºè¯¦ç»†æ—¥å¿—
            )

            print(f"âœ… TTS inference completed: {output_path}")
            return output_path

        # ============================================
        # æ–¹æ¡ˆBï¼šå¦‚æœä½ çš„æ¨¡å‹æœ‰ä¸åŒçš„è°ƒç”¨æ–¹å¼
        # ============================================
        elif hasattr(tts_model, 'synthesize'):
            # æŸäº›TTSåº“å¯èƒ½ä½¿ç”¨synthesizeæ–¹æ³•
            result = await tts_model.synthesize(
                text=text,
                reference_audio=spk_audio_path,
                emotion_audio=spk_audio_path,
                emotion_weight=emo_alpha,
                output_file=output_path,
                max_tokens_per_sentence=max_tokens
            )
            return result

        # ============================================
        # æ–¹æ¡ˆCï¼šå¦‚æœæ˜¯VLLMå°è£…çš„è°ƒç”¨æ–¹å¼
        # ============================================
        elif hasattr(tts_model, 'generate'):
            # VLLMé£æ ¼çš„è°ƒç”¨
            result = await tts_model.generate(
                prompt_audio=spk_audio_path,
                text=text,
                output_path=output_path,
                emotion_strength=emo_alpha
            )
            return result

        # ============================================
        # æ–¹æ¡ˆDï¼šå¦‚æœæ˜¯HTTP APIè°ƒç”¨
        # ============================================
        else:
            # å¦‚æœä½ çš„TTSæ˜¯é€šè¿‡HTTP APIè°ƒç”¨çš„
            import aiohttp

            async with aiohttp.ClientSession() as session:
                data = {
                    "text": text,
                    "spk_audio_path": spk_audio_path,
                    "emo_audio_path": spk_audio_path,
                    "emo_alpha": emo_alpha,
                    "max_text_tokens_per_sentence": max_tokens
                }

                async with session.post("http://localhost:8000/tts", json=data) as resp:
                    result = await resp.json()
                    return result["output_path"]

    except Exception as e:
        raise Exception(f"TTS inference failed: {str(e)}")

# ============================================
# åŒæ ·éœ€è¦ä¿®æ”¹çš„å…¶ä»–TTSè°ƒç”¨å‡½æ•°
# ============================================

async def tts_inference_with_emotion_ref(text: str, spk_audio_path: str, emo_audio_path: str, emo_alpha: float, max_tokens: int):
    """ä½¿ç”¨ç‹¬ç«‹çš„éŸ³è‰²å’Œæƒ…æ„Ÿå‚è€ƒéŸ³é¢‘"""
    try:
        output_filename = f"tts_output_{int(time.time() * 1000)}.wav"
        output_path = f"/tmp/{output_filename}"

        if hasattr(tts_model, 'infer'):
            # å®˜æ–¹IndexTTS 2.0 APIè°ƒç”¨æ–¹å¼
            result = tts_model.infer(
                spk_audio_prompt=spk_audio_path,    # éŸ³è‰²å‚è€ƒ
                emo_audio_prompt=emo_audio_path,    # ç‹¬ç«‹çš„æƒ…æ„Ÿå‚è€ƒ
                emo_alpha=emo_alpha,               # æƒ…æ„Ÿå¼ºåº¦
                text=text,
                output_path=output_path,
                max_text_tokens_per_sentence=max_tokens
            )
            return output_path
        else:
            # å…¶ä»–è°ƒç”¨æ–¹å¼...
            pass

    except Exception as e:
        raise Exception(f"TTS inference with emotion failed: {str(e)}")

# ============================================
# å¦‚ä½•ç¡®å®šä½¿ç”¨å“ªç§è°ƒç”¨æ–¹å¼ï¼Ÿ
# ============================================

# 1. æ£€æŸ¥ä½ å½“å‰api_server_v2.pyä¸­çš„TTSè°ƒç”¨ä»£ç 
# 2. æŸ¥çœ‹ä½ çš„TTSæ¨¡å‹å¯¹è±¡æœ‰å“ªäº›æ–¹æ³•ï¼š
#    - print(dir(tts_model))  # æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨æ–¹æ³•
# 3. æŸ¥çœ‹åŸæœ‰çš„å·¥ä½œä»£ç æ˜¯å¦‚ä½•è°ƒç”¨TTSçš„

# å¸¸è§çš„æ–¹æ³•åç§°ï¼š
# - tts_model.infer()           # IndexTTSå®˜æ–¹
# - tts_model.synthesize()      # é€šç”¨TTSåº“
# - tts_model.generate()        # VLLMé£æ ¼
# - tts_model.text_to_speech()  # å…¶ä»–åº“